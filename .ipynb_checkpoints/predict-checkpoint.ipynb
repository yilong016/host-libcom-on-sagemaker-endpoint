{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6612e6f-4a16-4a17-8db1-40f2e16d43d1",
   "metadata": {},
   "source": [
    "## prepare images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814747cf-5601-4a08-9bd3-494cd556d77b",
   "metadata": {},
   "source": [
    "## Use three models to demonstrate a typical images composition use case\n",
    "1. FOPAHeatMapModel can predict the rationality scores for all locations/scales given a background-foreground pair, and output the composite image with optimal location/scale.\n",
    "2. ImageHarmonizationModel adjusts the foreground illumination to be compatible the background given photorealistic background and photorealistic foreground.\n",
    "3. ShadowGenerationModel generates plausible shadow for the inserted object in a composite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdea54-1710-4aea-a3db-fcd5206209c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a sagemaker runtie client ready to inference\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize SageMaker runtime client\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Define the endpoint name\n",
    "endpoint_name = 'libcom'\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "from utils.process_image import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fb19d-8853-4f3b-951a-6945cb52313f",
   "metadata": {},
   "source": [
    "#### Provide a foreground image, a background image, and a foreground mask to obtain a heatmap and an automatically composited image of the foreground and background. There are various methods to obtain the mask, such as SAM. Note that the foreground mask generated by SAM has black as the foreground, and it needs to be converted into a mask where the foreground part is white for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f18ecd-0c07-4765-8f44-e42300ea808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If we obtaining a mask image from SAM, we need to invert the black and white pixels of the mask. In the mask used by Libcom, the foreground pixels are white.\n",
    "import cv2\n",
    "test_dir  = 'uploads/'\n",
    "image=cv2.imread(test_dir+'comp_mask_black.jpg')\n",
    "inverted_image=cv2.bitwise_not(image)\n",
    "cv2.imwrite(test_dir+'comp_mask.png',inverted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbb1dc-2a6a-49a3-b2de-3fb0e3494f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Generate FOPA image and placement suggestion\n",
    "background_path = \"uploads/bg.png\"\n",
    "foreground_path = \"uploads/fg.jpg\"\n",
    "foreground_mask_path = \"uploads/fg_mask.png\"\n",
    "bg=encode_image(background_path)\n",
    "fg=encode_image(foreground_path)\n",
    "fg_mask=encode_image(foreground_mask_path)\n",
    "\n",
    "function = \"heatmap_compose\"\n",
    "\n",
    "payload = {\n",
    "    \"function\":function,\n",
    "    \"background\":bg,\n",
    "    \"foreground\":fg,\n",
    "    \"foreground_mask\":fg_mask\n",
    "}\n",
    "\n",
    "# Prepare the request body as a JSON object\n",
    "request_body = json.dumps(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e94007-fb4b-4a46-a003-4b1aaadd3c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send the inference request to the endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=request_body,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "fopa_result = json.loads(response_body)\n",
    "\n",
    "bbox=fopa_result['bboxes']\n",
    "print(bbox)\n",
    "heatmap=save_image_from_base64(fopa_result['heatmap_image'],'results','heatmap')\n",
    "comp_img=save_image_from_base64(fopa_result['comp_image'],'results','heatmap')\n",
    "comp_mask=save_image_from_base64(fopa_result['comp_mask'],'results','heatmap')\n",
    "grid_img  = make_image_grid([heatmap, comp_img, comp_mask])\n",
    "\n",
    "from IPython.display import display,Image\n",
    "\n",
    "cv2.imwrite(heatmap, grid_img)\n",
    "display(Image(filename=heatmap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622054c-9c99-489b-abd8-b6b39f5fa652",
   "metadata": {},
   "source": [
    "### Image Compose Request\n",
    "you can also call compose function directly with on demand positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716641bb-1102-4293-9269-84d6154de499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare images\n",
    "background_path = \"uploads/bg.png\"\n",
    "foreground_path = \"uploads/fg.jpg\"\n",
    "foreground_mask_path = \"uploads/fg_mask.png\"\n",
    "bg=encode_image(background_path)\n",
    "fg=encode_image(foreground_path)\n",
    "fg_mask=encode_image(foreground_mask_path)\n",
    "\n",
    "function = \"simple_compose\"\n",
    "\n",
    "bbox = [376, 187, 550, 791]\n",
    "\n",
    "print(bbox)\n",
    "payload = {\n",
    "    \"function\":function,\n",
    "    \"background\":bg,\n",
    "    \"foreground\":fg,\n",
    "    \"foreground_mask\":fg_mask,\n",
    "    \"bbox\":bbox\n",
    "}\n",
    "# Prepare the request body as a JSON object\n",
    "request_body = json.dumps(payload)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ba3f4-ba30-428a-b273-4c12865cfea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare function to encode and decode images to process inference request and response\n",
    "\n",
    "# Send Image Compose inference request to the endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=request_body,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "compose_result = json.loads(response_body)\n",
    "\n",
    "# Process the result\n",
    "#decode_image(compose_result['comp_image'])\n",
    "#decode_image(compose_result['comp_mask'])\n",
    "\n",
    "comp_image=save_image_from_base64(compose_result['comp_image'],'results','comp_image')\n",
    "grid_img  = make_image_grid([foreground_path, background_path, comp_image])\n",
    "\n",
    "from IPython.display import display,Image\n",
    "\n",
    "cv2.imwrite(comp_image, grid_img)\n",
    "display(Image(filename=comp_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c46e31-3227-4f2c-8f51-fbfe5ce3c6a1",
   "metadata": {},
   "source": [
    "## Image Harmonization using PCTNet and CDTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65557a05-bb9e-4e87-8240-924cd1337f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose cdt mode\n",
    "\n",
    "comp_image_path = \"uploads/comp_image.png\"\n",
    "comp_mask_path = \"uploads/comp_mask.png\"\n",
    "comp_image=encode_image(comp_image_path)\n",
    "comp_mask=encode_image(comp_mask_path)\n",
    "\n",
    "function = \"cdt_mode\"\n",
    "\n",
    "payload = {\n",
    "    \"function\":function,\n",
    "    \"comp_image\":comp_image,\n",
    "    \"comp_mask\":comp_mask\n",
    "}\n",
    "\n",
    "#payload\n",
    "# Prepare the request body as a JSON object\n",
    "request_body = json.dumps(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89c367-f0f1-4979-a178-bd32a111bed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send the inference request to the endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=request_body,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "harmony_result = json.loads(response_body)\n",
    "\n",
    "# Process the result\n",
    "#decode_image(harmony_result['pct_result'])\n",
    "\n",
    "harmony_image=save_image_from_base64(harmony_result['cdt_result'],'results','harmony')\n",
    "grid_img  = make_image_grid([comp_image_path, harmony_image])\n",
    "\n",
    "from IPython.display import display,Image\n",
    "\n",
    "cv2.imwrite(harmony_image, grid_img)\n",
    "display(Image(filename=harmony_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c13a78-fac2-419c-b52a-ef7bd44dbe5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose pct mode\n",
    "\n",
    "comp_image_path = \"uploads/comp_image.png\"\n",
    "comp_mask_path = \"uploads/comp_mask.png\"\n",
    "comp_image=encode_image(comp_image_path)\n",
    "comp_mask=encode_image(comp_mask_path)\n",
    "\n",
    "function = \"pct_mode\"\n",
    "\n",
    "payload = {\n",
    "    \"function\":function,\n",
    "    \"comp_image\":comp_image,\n",
    "    \"comp_mask\":comp_mask\n",
    "}\n",
    "\n",
    "#payload\n",
    "# Prepare the request body as a JSON object\n",
    "request_body = json.dumps(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc68e0d-aea9-408a-bc97-e3fcc584bb52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send the inference request to the endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=request_body,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "harmony_result = json.loads(response_body)\n",
    "\n",
    "# Process the result\n",
    "#print(\"Inference result:\", harmony_result)\n",
    "#decode_image(harmony_result['pct_result'])\n",
    "\n",
    "harmony_image=save_image_from_base64(harmony_result['pct_result'],'results','harmony')\n",
    "grid_img  = make_image_grid([comp_image_path, harmony_image])\n",
    "\n",
    "from IPython.display import display,Image\n",
    "\n",
    "cv2.imwrite(harmony_image, grid_img)\n",
    "display(Image(filename=harmony_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06862ce6-cdeb-4c70-aee8-7395321df40e",
   "metadata": {},
   "source": [
    "## Shadow Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d8981-40ce-4038-8c0a-ba7588608a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate shadow\n",
    "comp_img = \"uploads/comp_image.png\"\n",
    "comp_mask = \"uploads/comp_mask.png\"\n",
    "comp_img_b64=encode_image(comp_img)\n",
    "comp_mask_b64=encode_image(comp_mask)\n",
    "\n",
    "function = \"gn_shadow\"\n",
    "number = 1\n",
    "\n",
    "payload = {\n",
    "    \"function\":function,\n",
    "    \"comp_image\":comp_img_b64,\n",
    "    \"comp_mask\":comp_mask_b64,\n",
    "    \"number\":number\n",
    "}\n",
    "#payload\n",
    "\n",
    "# Prepare the request body as a JSON object\n",
    "request_body = json.dumps(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ee6d9-9eb7-44ae-a070-d8d0fe53179c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send the inference request to the endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=request_body,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the response\n",
    "response_body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "shadow_result = json.loads(response_body)\n",
    "\n",
    "# Process the result\n",
    "#print(\"Inference result:\", shadow_result)\n",
    "\n",
    "shadow_image=save_image_from_base64(shadow_result['shadow'],'results','shadow')\n",
    "grid_img  = make_image_grid([comp_image_path, shadow_image])\n",
    "\n",
    "from IPython.display import display,Image\n",
    "\n",
    "cv2.imwrite(shadow_image, grid_img)\n",
    "display(Image(filename=shadow_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
